{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chap 5Test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNk8ef9hDFH5QPGYr1hoIF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shindora/NLP-with-PyTorch/blob/master/Chap_5Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqtcDEgefKAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "082b4b70-1482-4b1f-b405-7d2233d69a73"
      },
      "source": [
        "!pip install annoy\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: annoy in /usr/local/lib/python3.6/dist-packages (1.16.3)\n",
            "--2020-04-22 07:08:55--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-22 07:08:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-22 07:08:55--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.02MB/s    in 6m 28s  \n",
            "\n",
            "2020-04-22 07:15:23 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rimMyU3Vwrcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "be65db5e-4c94-4643-9428-526ba1a0f9e3"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciJFXT6bbUcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from annoy import AnnoyIndex\n",
        "class PreTrainedEmbeddings(object):\n",
        "  def  __init__(self, word_to_index, word_vectors):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    word_to_index (dict): mapping from word to integers\n",
        "    word_vectors (list of numpy arrays)\n",
        "    \"\"\"\n",
        "    self.word_to_index = word_to_index\n",
        "    self.word_vectors = word_vectors\n",
        "    self.index_to_word = \\\n",
        "      {v: k for k, v in self.word_to_index.items()}\n",
        "    self.index = AnnoyIndex(len(word_vectors[0]),\n",
        "                            metric='euclidean')\n",
        "    for _, i in self.word_to_index.items():\n",
        "      self.index.add_item(i, self.word_vectors[i])\n",
        "    self.index.build(50)\n",
        "  @classmethod\n",
        "  def from_embeddings_file(cls, embedding_file):\n",
        "    \"\"\"Instantiate from pretrained vector file.\n",
        "    Vector file should be of the format:\n",
        "    word0 x0_0 x0_1 x0_2 x0_3 ... x0_N\n",
        "    word1 x1_0 x1_1 x1_2 x1_3 ... x1_N\n",
        "    Args:\n",
        "    embedding_file (str): location of the file\n",
        "    Returns:\n",
        "    instance of PretrainedEmbeddings\n",
        "    \"\"\"\n",
        "    word_to_index = {}\n",
        "    word_vectors = []\n",
        "    with open(embedding_file) as fp:\n",
        "      for line in fp.readlines():\n",
        "        line = line.split(\" \")\n",
        "        word = line[0]\n",
        "        vec = np.array([float(x) for x in line[1:]])\n",
        "        word_to_index[word] = len(word_to_index)\n",
        "        word_vectors.append(vec)\n",
        "      return cls(word_to_index, word_vectors)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h6dvkXTgU2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = \\\n",
        "  PreTrainedEmbeddings.from_embeddings_file('glove.6B.100d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "749RxGebo9ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from annoy import AnnoyIndex\n",
        "class PreTrainedEmbeddings(object):\n",
        "  \"\"\" implementation continued from previous code example\"\"\"\n",
        "  def get_embedding(self, word):\n",
        "        return self.word_vectors[self.word_to_index[word]]\n",
        "  def get_closest_to_vector(self, vector, n=1):\n",
        "    \"\"\"Given a vector, return its n nearest neighbors\n",
        "    Args:\n",
        "    vector (np.ndarray): should match the size of the vectors\n",
        "    in the Annoy index\n",
        "    n (int): the number of neighbors to return\n",
        "    Returns:\n",
        "    [str, str, ...]: words nearest to the given vector\n",
        "    The words are not ordered by distance\n",
        "    \"\"\"\n",
        "    nn_indices = self.index.get_nns_by_vector(vector, n)\n",
        "    return [self.index_to_word[neighbor]\n",
        "            for neighbor in nn_indices]\n",
        "def compute_and_print_analogy(self, word1, word2, word3):\n",
        "  \"\"\"Prints the solutions to analogies using word embeddings\n",
        "  Analogies are word1 is to word2 as word3 is to __\n",
        "  This method will print: word1 : word2 :: word3 : word4\n",
        "  Args:\n",
        "  word1 (str)\n",
        "  word2 (str)\n",
        "  word3 (str)\n",
        "  \"\"\"\n",
        "  vec1 = self.get_embedding(word1)\n",
        "  vec2 = self.get_embedding(word2)\n",
        "  vec3 = self.get_embedding(word3)\n",
        "  # Simple hypothesis: Analogy is a spatial relationship\n",
        "  spatial_relationship = vec2 - vec1\n",
        "  vec4 = vec3 + spatial_relationship\n",
        "  closest_words = self.get_closest_to_vector(vec4, n=4)\n",
        "  existing_words = set([word1, word2, word3])\n",
        "  closest_words = [word for word in closest_words\n",
        "            if word not in existing_words]\n",
        "  if len(closest_words) == 0:\n",
        "        print(\"Could not find nearest neighbors for the vector!\")\n",
        "        return\n",
        "  for word4 in closest_words:\n",
        "        print(\"{} : {} :: {} : {}\".format(word1, word2, word3,word4))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kauKaepqGxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "38d04bb0-5dfc-42b8-ca6b-3140b7b27ae0"
      },
      "source": [
        "Relationship 2: Verb­noun relationshipsembeddings.compute_and_print_analogy('fly', 'plane', 'sail')\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-a2c69110005d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Relationship 2: Verb­noun relationshipsembeddings.compute_and_print_analogy('fly', 'plane', 'sail')\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}